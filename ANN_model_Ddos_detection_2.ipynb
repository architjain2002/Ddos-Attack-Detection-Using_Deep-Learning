{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "feature_list = dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape  \n",
    "dataset = dataset.replace(np.inf,np.nan)    # replacing inf with nan\n",
    "dataset = dataset.fillna(dataset.mean(numeric_only=True)) # ghen converting nan to mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (225745, 78)\n",
      "shape of Y (225745,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "print(\"shape of X\",X.shape)\n",
    "\n",
    "Y = dataset.iloc[:,-1].values\n",
    "print(\"shape of Y\",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is NaN present: False\n",
      "is inf present: False\n"
     ]
    }
   ],
   "source": [
    "print(\"is NaN present:\",np.any(np.isnan(X)))  # to check whether the array contains nan\n",
    "print(\"is inf present:\",np.any(np.isinf(X)))  # to check whether the array contains inf\n",
    "X[X < 0] = 0   # to replace all negative values with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest  # feature selection\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Selected_columns  Score_chi2\n",
      "4    Total Length of Fwd Packets    0.652149\n",
      "63             Subflow Fwd Bytes    0.651838\n",
      "52           Average Packet Size    0.563239\n",
      "65             Subflow Bwd Bytes    0.548846\n",
      "5    Total Length of Bwd Packets    0.548763\n",
      "54          Avg Bwd Segment Size    0.546163\n",
      "12        Bwd Packet Length Mean    0.544214\n",
      "34             Fwd Header Length    0.544106\n",
      "55           Fwd Header Length.1    0.543104\n",
      "0               Destination Port    0.537811\n",
      "10         Bwd Packet Length Max    0.528891\n",
      "66        Init_Win_bytes_forward    0.498008\n",
      "53          Avg Fwd Segment Size    0.490438\n",
      "8         Fwd Packet Length Mean    0.490237\n",
      "6          Fwd Packet Length Max    0.486361\n",
      "35             Bwd Header Length    0.476146\n",
      "23                   Fwd IAT Max    0.460180\n",
      "20                 Fwd IAT Total    0.458332\n",
      "21                  Fwd IAT Mean    0.447133\n",
      "2              Total Fwd Packets    0.410258\n",
      "62           Subflow Fwd Packets    0.409620\n",
      "22                   Fwd IAT Std    0.405412\n",
      "68              act_data_pkt_fwd    0.401213\n",
      "40            Packet Length Mean    0.395725\n",
      "42        Packet Length Variance    0.369730\n",
      "41             Packet Length Std    0.369687\n",
      "28                   Bwd IAT Max    0.356855\n",
      "25                 Bwd IAT Total    0.353443\n",
      "67       Init_Win_bytes_backward    0.349830\n",
      "9          Fwd Packet Length Std    0.349305\n",
      "13         Bwd Packet Length Std    0.347634\n",
      "37                 Bwd Packets/s    0.342126\n",
      "26                  Bwd IAT Mean    0.330811\n",
      "64           Subflow Bwd Packets    0.329292\n",
      "3         Total Backward Packets    0.328367\n",
      "36                 Fwd Packets/s    0.323937\n",
      "39             Max Packet Length    0.298765\n",
      "1                  Flow Duration    0.296161\n",
      "14                  Flow Bytes/s    0.293264\n",
      "11         Bwd Packet Length Min    0.273031\n",
      "18                  Flow IAT Max    0.254327\n",
      "17                  Flow IAT Std    0.251312\n",
      "15                Flow Packets/s    0.247635\n",
      "16                 Flow IAT Mean    0.241661\n",
      "27                   Bwd IAT Std    0.238778\n",
      "73                    Active Min    0.179675\n",
      "29                   Bwd IAT Min    0.179614\n",
      "70                   Active Mean    0.176899\n",
      "72                    Active Max    0.172735\n",
      "24                   Fwd IAT Min    0.160189\n"
     ]
    }
   ],
   "source": [
    "bestfeatures = SelectKBest(score_func = mutual_info_classif, k=50)\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "#create df for scores\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "#create df for column names\n",
    "dfcolumns = pd.DataFrame(feature_list)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "\n",
    "#naming the dataframe columns\n",
    "featureScores.columns = ['Selected_columns','Score_chi2']  \n",
    "#print 50 best features\n",
    "print(featureScores.nlargest(50,'Score_chi2')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "          4     63   52   65   5    54   12    34    55       0   ...  \\\n",
      "0       12.0  12.0  9.0  0.0  0.0  0.0  0.0  40.0  40.0  54865.0  ...   \n",
      "1        6.0   6.0  9.0  6.0  6.0  6.0  6.0  20.0  20.0  55054.0  ...   \n",
      "2        6.0   6.0  9.0  6.0  6.0  6.0  6.0  20.0  20.0  55055.0  ...   \n",
      "3        6.0   6.0  9.0  6.0  6.0  6.0  6.0  20.0  20.0  46236.0  ...   \n",
      "4       12.0  12.0  9.0  0.0  0.0  0.0  0.0  40.0  40.0  54863.0  ...   \n",
      "...      ...   ...  ...  ...  ...  ...  ...   ...   ...      ...  ...   \n",
      "225740   6.0   6.0  9.0  6.0  6.0  6.0  6.0  20.0  20.0  61374.0  ...   \n",
      "225741   6.0   6.0  9.0  6.0  6.0  6.0  6.0  20.0  20.0  61378.0  ...   \n",
      "225742   6.0   6.0  9.0  6.0  6.0  6.0  6.0  20.0  20.0  61375.0  ...   \n",
      "225743  12.0  12.0  9.0  0.0  0.0  0.0  0.0  40.0  40.0  61323.0  ...   \n",
      "225744   6.0   6.0  9.0  6.0  6.0  6.0  6.0  20.0  20.0  61326.0  ...   \n",
      "\n",
      "                   36   39     1             14   11     18   17  \\\n",
      "0       666666.666700  6.0    3.0  4.000000e+06  0.0    3.0  0.0   \n",
      "1         9174.311927  6.0  109.0  1.100917e+05  6.0  109.0  0.0   \n",
      "2        19230.769230  6.0   52.0  2.307692e+05  6.0   52.0  0.0   \n",
      "3        29411.764710  6.0   34.0  3.529412e+05  6.0   34.0  0.0   \n",
      "4       666666.666700  6.0    3.0  4.000000e+06  0.0    3.0  0.0   \n",
      "...               ...  ...    ...           ...  ...    ...  ...   \n",
      "225740   16393.442620  6.0   61.0  1.967213e+05  6.0   61.0  0.0   \n",
      "225741   13888.888890  6.0   72.0  1.666667e+05  6.0   72.0  0.0   \n",
      "225742   13333.333330  6.0   75.0  1.600000e+05  6.0   75.0  0.0   \n",
      "225743   41666.666670  6.0   48.0  2.500000e+05  0.0   48.0  0.0   \n",
      "225744   14705.882350  6.0   68.0  1.764706e+05  6.0   68.0  0.0   \n",
      "\n",
      "                  15     16   27  \n",
      "0       666666.66670    3.0  0.0  \n",
      "1        18348.62385  109.0  0.0  \n",
      "2        38461.53846   52.0  0.0  \n",
      "3        58823.52941   34.0  0.0  \n",
      "4       666666.66670    3.0  0.0  \n",
      "...              ...    ...  ...  \n",
      "225740   32786.88525   61.0  0.0  \n",
      "225741   27777.77778   72.0  0.0  \n",
      "225742   26666.66667   75.0  0.0  \n",
      "225743   41666.66667   48.0  0.0  \n",
      "225744   29411.76471   68.0  0.0  \n",
      "\n",
      "[225745 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(featureScores.nlargest(50,'Score_chi2').Selected_columns.values)\n",
    "featureScore_after_filter = featureScores.nlargest(50,'Score_chi2')\n",
    "print(featureScore_after_filter.index[0])\n",
    "count = 0\n",
    "ind = []\n",
    "for i in featureScore_after_filter.Score_chi2:\n",
    "    if i < 0.2:\n",
    "        ind.append(featureScore_after_filter.index[count])\n",
    "    count = count + 1\n",
    "featureScore_after_filter = featureScore_after_filter.drop(ind,axis = 0)  # contains all the filtered features\n",
    "X = pd.DataFrame(X)\n",
    "X = X.loc[:,featureScore_after_filter.index] # contains data after filter from feature selection\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y= LabelEncoder()  \n",
    "Y = labelencoder_y.fit_transform(Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(X, Y, test_size= 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # scaling of the data\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "x_train_scaled = scaler_X.fit_transform(x_train) # preprocessed training data\n",
    "x_test_scaled = scaler_X.fit_transform(x_test) # preprocessed testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, input_shape=(45,), activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/') # to save weights in the middle of a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2822/2822 [==============================] - 19s 6ms/step - loss: 0.0190 - accuracy: 0.9952\n",
      "Epoch 2/10\n",
      "2822/2822 [==============================] - 17s 6ms/step - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 3/10\n",
      "2822/2822 [==============================] - 19s 7ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "2822/2822 [==============================] - 18s 6ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "2822/2822 [==============================] - 17s 6ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "2822/2822 [==============================] - 18s 6ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "2822/2822 [==============================] - 18s 6ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "2822/2822 [==============================] - 18s 6ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "2822/2822 [==============================] - 18s 6ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "2822/2822 [==============================] - 18s 6ms/step - loss: 0.0023 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1af2987bc70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "model.fit(x_train_scaled, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Weights/Model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Weights/Model_1')  # to save weights as an entire weights\n",
    "\n",
    "# or this is as well works but it stores it in diff format\n",
    "# model.save('Weights_in_h5_format/weights_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 4s 5ms/step - loss: 0.0028 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0028153432067483664, 0.9993577003479004]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled,64)\n",
    "y_pred = np.argmax(y_pred,axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993576823406941"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27738582, -0.27738582,  1.14408913,  0.137769  ,  0.137769  ,\n",
       "         0.92878733,  0.92878733, -0.10679647, -0.10679647, -0.44589202,\n",
       "         0.83919496,  0.47512355, -0.3093438 , -0.3093438 , -0.2792493 ,\n",
       "         0.04532061, -0.47598851, -0.49096568, -0.43305804, -0.11647557,\n",
       "        -0.11647557, -0.4847499 , -0.09525446,  1.15679871,  0.43595419,\n",
       "         0.82929725, -0.27922469, -0.29759103, -0.09307815, -0.25782377,\n",
       "         0.75655787, -0.08823673, -0.20570462,  0.0569975 ,  0.0569975 ,\n",
       "        -0.11249304,  0.68596957, -0.51605685, -0.02475563, -0.31669887,\n",
       "        -0.50487211, -0.55649425, -0.12234392, -0.58359852, -0.28901442]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(x_test_scaled[2].reshape(1,-1))\n",
    "x_test_scaled[2].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22480/2626192408.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_recieved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m18885\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m  \u001b[1;31m# to test a particular value on when recieved from IOT device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_recieved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_recieved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_recieved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_recieved\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatureScore_after_filter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_recieved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_recieved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_recieved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_recieved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "X_recieved = dataset.iloc[18885,:-1].values  # to test a particular value on when recieved from IOT device\n",
    "X_recieved = pd.DataFrame(X_recieved)\n",
    "X_recieved = X_recieved.loc[featureScore_after_filter.index,:]\n",
    "X_recieved = np.array(X_recieved).reshape(1,-1)\n",
    "X_recieved = np.asarray(X_recieved).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadModel = tf.keras.models.load_model('Weights_in_h5_format/weights_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                2944      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,090\n",
      "Trainable params: 5,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loadModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = loadModel.predict(X_recieved)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message_id': '01GH9V233DGX5G281JTHKB9RB0', 'accepted_time': '2022-11-07T20:03:42.829Z'}\n"
     ]
    }
   ],
   "source": [
    "# SMS service\n",
    "import requests\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if(pred[0][1] == 1):\n",
    "  load_dotenv()\n",
    "  appId = os.getenv('APPID')\n",
    "  accessKey = os.getenv('ACCESSKEY')\n",
    "  accessSecret = os.getenv('ACCESSSECRET')\n",
    "  projectId = os.getenv('PROJECTID')\n",
    "  channel = \"SMS\"\n",
    "  identity = \"+918792884722\"\n",
    "  url = \"https://us.conversation.api.sinch.com/v1/projects/\" + projectId + \"/messages:send\"\n",
    "\n",
    "  data = accessKey + \":\" + accessSecret\n",
    "  encodedBytes = base64.b64encode(data.encode(\"utf-8\"))\n",
    "  accessToken = str(encodedBytes, \"utf-8\")\n",
    "\n",
    "  payload = {\n",
    "    \"app_id\": appId,\n",
    "    \"recipient\": {\n",
    "        \"identified_by\": {\n",
    "            \"channel_identities\": [\n",
    "              {\n",
    "                  \"channel\": channel,\n",
    "                  \"identity\": identity\n",
    "              }  \n",
    "              ]\n",
    "        }\n",
    "    },\n",
    "    \"message\": {\n",
    "        \"text_message\": {\n",
    "            \"text\": \"Ddos Attack Detected. Kindly take necessary action.\"\n",
    "        }\n",
    "    }  \n",
    "  }\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Basic \" + accessToken\n",
    "  }\n",
    "\n",
    "  response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "  data = response.json()\n",
    "  print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email service\n",
    "\n",
    "import smtplib\n",
    "\n",
    "if(pred[0][1] == 1):\n",
    "    # creates SMTP session\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    \n",
    "    # start TLS for security\n",
    "    s.starttls()\n",
    "    \n",
    "    # Authentication\n",
    "    s.login(\"adigupta239@gmail.com\", \"mxwzguwzdcxcrqdw\")\n",
    "    \n",
    "    # message to be sent\n",
    "    subject = \"Suspicious activity detected on your network\"\n",
    "    text = 'Dear user, our model have detected some malicious traffic on your network which could be a possible attempt of a DDOS attack. You can perform the following action :\\n \\n 1.Disconnect all your devices from the network.\\n 2.Check if any unknown software is installed on your device. \\n 3.Contact a security personnel ASAP. \\n  \\nHope you find this alert helpful and took the action at right time.'\n",
    "\n",
    "    message = 'Subject: {}\\n\\n{}'.format(subject, text)\n",
    "\n",
    "    # sending the mail\n",
    "    s.sendmail(\"adigupta239@gmail.com\", \"arcyjain2002@gmail.com\", message)\n",
    "    \n",
    "    # terminating the session\n",
    "    s.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d63a252d2e56e2221730629e17258d19c2d81c88b56f94c769864d195f781b56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
