{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "feature_list = dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape  \n",
    "dataset = dataset.replace(np.inf,np.nan)    # replacing inf with nan\n",
    "dataset = dataset.fillna(dataset.mean(numeric_only=True)) # ghen converting nan to mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (225745, 78)\n",
      "shape of Y (225745,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "print(\"shape of X\",X.shape)\n",
    "\n",
    "Y = dataset.iloc[:,-1].values\n",
    "print(\"shape of Y\",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is NaN present: False\n",
      "is inf present: False\n"
     ]
    }
   ],
   "source": [
    "print(\"is NaN present:\",np.any(np.isnan(X)))  # to check whether the array contains nan\n",
    "print(\"is inf present:\",np.any(np.isinf(X)))  # to check whether the array contains inf\n",
    "X[X < 0] = 0   # to replace all negative values with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest  # feature selection\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Selected_columns  Score_chi2\n",
      "4    Total Length of Fwd Packets    0.652321\n",
      "63             Subflow Fwd Bytes    0.652271\n",
      "52           Average Packet Size    0.563413\n",
      "5    Total Length of Bwd Packets    0.548778\n",
      "65             Subflow Bwd Bytes    0.548703\n",
      "12        Bwd Packet Length Mean    0.544560\n",
      "34             Fwd Header Length    0.544465\n",
      "54          Avg Bwd Segment Size    0.544073\n",
      "55           Fwd Header Length.1    0.543935\n",
      "0               Destination Port    0.538541\n",
      "10         Bwd Packet Length Max    0.528925\n",
      "66        Init_Win_bytes_forward    0.496586\n",
      "53          Avg Fwd Segment Size    0.490605\n",
      "8         Fwd Packet Length Mean    0.489709\n",
      "6          Fwd Packet Length Max    0.485860\n",
      "35             Bwd Header Length    0.475500\n",
      "23                   Fwd IAT Max    0.460042\n",
      "20                 Fwd IAT Total    0.457025\n",
      "21                  Fwd IAT Mean    0.447676\n",
      "2              Total Fwd Packets    0.410077\n",
      "62           Subflow Fwd Packets    0.409837\n",
      "22                   Fwd IAT Std    0.405084\n",
      "68              act_data_pkt_fwd    0.399651\n",
      "40            Packet Length Mean    0.395631\n",
      "42        Packet Length Variance    0.369561\n",
      "41             Packet Length Std    0.368331\n",
      "28                   Bwd IAT Max    0.356883\n",
      "25                 Bwd IAT Total    0.353274\n",
      "67       Init_Win_bytes_backward    0.350604\n",
      "9          Fwd Packet Length Std    0.349875\n",
      "13         Bwd Packet Length Std    0.346099\n",
      "37                 Bwd Packets/s    0.341996\n",
      "26                  Bwd IAT Mean    0.330387\n",
      "3         Total Backward Packets    0.330387\n",
      "64           Subflow Bwd Packets    0.330031\n",
      "36                 Fwd Packets/s    0.323987\n",
      "39             Max Packet Length    0.298615\n",
      "1                  Flow Duration    0.296206\n",
      "14                  Flow Bytes/s    0.293447\n",
      "11         Bwd Packet Length Min    0.273065\n",
      "18                  Flow IAT Max    0.253208\n",
      "17                  Flow IAT Std    0.251557\n",
      "15                Flow Packets/s    0.247792\n",
      "16                 Flow IAT Mean    0.241700\n",
      "27                   Bwd IAT Std    0.238264\n",
      "73                    Active Min    0.181977\n",
      "29                   Bwd IAT Min    0.178937\n",
      "70                   Active Mean    0.176820\n",
      "72                    Active Max    0.171033\n",
      "24                   Fwd IAT Min    0.160126\n"
     ]
    }
   ],
   "source": [
    "bestfeatures = SelectKBest(score_func = mutual_info_classif, k=50)\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "#create df for scores\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "#create df for column names\n",
    "dfcolumns = pd.DataFrame(feature_list)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "\n",
    "#naming the dataframe columns\n",
    "featureScores.columns = ['Selected_columns','Score_chi2']  \n",
    "#print 50 best features\n",
    "print(featureScores.nlargest(50,'Score_chi2')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "          4     63   52   5    65   12    34   54    55       0   ...  \\\n",
      "0       12.0  12.0  9.0  0.0  0.0  0.0  40.0  0.0  40.0  54865.0  ...   \n",
      "1        6.0   6.0  9.0  6.0  6.0  6.0  20.0  6.0  20.0  55054.0  ...   \n",
      "2        6.0   6.0  9.0  6.0  6.0  6.0  20.0  6.0  20.0  55055.0  ...   \n",
      "3        6.0   6.0  9.0  6.0  6.0  6.0  20.0  6.0  20.0  46236.0  ...   \n",
      "4       12.0  12.0  9.0  0.0  0.0  0.0  40.0  0.0  40.0  54863.0  ...   \n",
      "...      ...   ...  ...  ...  ...  ...   ...  ...   ...      ...  ...   \n",
      "225740   6.0   6.0  9.0  6.0  6.0  6.0  20.0  6.0  20.0  61374.0  ...   \n",
      "225741   6.0   6.0  9.0  6.0  6.0  6.0  20.0  6.0  20.0  61378.0  ...   \n",
      "225742   6.0   6.0  9.0  6.0  6.0  6.0  20.0  6.0  20.0  61375.0  ...   \n",
      "225743  12.0  12.0  9.0  0.0  0.0  0.0  40.0  0.0  40.0  61323.0  ...   \n",
      "225744   6.0   6.0  9.0  6.0  6.0  6.0  20.0  6.0  20.0  61326.0  ...   \n",
      "\n",
      "                   36   39     1             14   11     18   17  \\\n",
      "0       666666.666700  6.0    3.0  4.000000e+06  0.0    3.0  0.0   \n",
      "1         9174.311927  6.0  109.0  1.100917e+05  6.0  109.0  0.0   \n",
      "2        19230.769230  6.0   52.0  2.307692e+05  6.0   52.0  0.0   \n",
      "3        29411.764710  6.0   34.0  3.529412e+05  6.0   34.0  0.0   \n",
      "4       666666.666700  6.0    3.0  4.000000e+06  0.0    3.0  0.0   \n",
      "...               ...  ...    ...           ...  ...    ...  ...   \n",
      "225740   16393.442620  6.0   61.0  1.967213e+05  6.0   61.0  0.0   \n",
      "225741   13888.888890  6.0   72.0  1.666667e+05  6.0   72.0  0.0   \n",
      "225742   13333.333330  6.0   75.0  1.600000e+05  6.0   75.0  0.0   \n",
      "225743   41666.666670  6.0   48.0  2.500000e+05  0.0   48.0  0.0   \n",
      "225744   14705.882350  6.0   68.0  1.764706e+05  6.0   68.0  0.0   \n",
      "\n",
      "                  15     16   27  \n",
      "0       666666.66670    3.0  0.0  \n",
      "1        18348.62385  109.0  0.0  \n",
      "2        38461.53846   52.0  0.0  \n",
      "3        58823.52941   34.0  0.0  \n",
      "4       666666.66670    3.0  0.0  \n",
      "...              ...    ...  ...  \n",
      "225740   32786.88525   61.0  0.0  \n",
      "225741   27777.77778   72.0  0.0  \n",
      "225742   26666.66667   75.0  0.0  \n",
      "225743   41666.66667   48.0  0.0  \n",
      "225744   29411.76471   68.0  0.0  \n",
      "\n",
      "[225745 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(featureScores.nlargest(50,'Score_chi2').Selected_columns.values)\n",
    "featureScore_after_filter = featureScores.nlargest(50,'Score_chi2')\n",
    "print(featureScore_after_filter.index[0])\n",
    "count = 0\n",
    "ind = []\n",
    "for i in featureScore_after_filter.Score_chi2:\n",
    "    if i < 0.2:\n",
    "        ind.append(featureScore_after_filter.index[count])\n",
    "    count = count + 1\n",
    "featureScore_after_filter = featureScore_after_filter.drop(ind,axis = 0)  # contains all the filtered features\n",
    "X = pd.DataFrame(X)\n",
    "X = X.loc[:,featureScore_after_filter.index] # contains data after filter from feature selection\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y= LabelEncoder()  \n",
    "Y = labelencoder_y.fit_transform(Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(X, Y, test_size= 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # scaling of the data\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "x_train_scaled = scaler_X.fit_transform(x_train) # preprocessed training data\n",
    "x_test_scaled = scaler_X.fit_transform(x_test) # preprocessed testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, input_shape=(45,), activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2822/2822 [==============================] - 27s 8ms/step - loss: 0.0183 - accuracy: 0.9960\n",
      "Epoch 2/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0048 - accuracy: 0.9988\n",
      "Epoch 3/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 4/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 6/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0032 - accuracy: 0.9992\n",
      "Epoch 7/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "2822/2822 [==============================] - 24s 8ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "2822/2822 [==============================] - 23s 8ms/step - loss: 0.0024 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ecd365790>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "model.fit(x_train_scaled, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 6s 8ms/step - loss: 0.0032 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0032083799596875906, 0.9992469549179077]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled,64)\n",
    "y_pred = np.argmax(y_pred,axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992469379166758"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d63a252d2e56e2221730629e17258d19c2d81c88b56f94c769864d195f781b56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
